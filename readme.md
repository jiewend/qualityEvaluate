- 预处理
	- 将处理工序的字符串转为数字，一共有13道处理工序
	- 将缺失的数据段补全
		- 整列缺失，补成1
		- 一列部分缺失，补成该列平均值
- 数据降维
	- 将数据切分为13部分，每道工序对应一部分
	- 分别对每部分数据进行降维处理，降维后维数分别为：62, 171, 5, 51, 132, 95, 27, 40, 65, 77, 16, 68, 33总维数降至842+13= 855个特征
- 整体思想
	- 每道工序使用不同神经网络学习，一共需要13个神经网络，每个神经网络都有一个输入层，一个掩藏层和一个输出层，13个输出层作为汇总神经网络的输入层。有一个问题待解决，13个神经网络分别要有多少个输出节点？
	- 暂时用一个神经网络，855个输入节点，855×2=1710个掩藏节点和一个输出节点。作出结果看看如何
	- 遇到问题，神经网络是用于解决的分类问题的，但是需要解决的问题是线性回归问题，解决方法有两个
		- 将问题转化为分类问题：需要很大型的神经网络，训练时间可能需要很久。效果不是很好，训练MSE最小到达0.043左右，可调参数好像就只有lamdba
			- 使用分类效果不好，提交的MSE在0.054和0.059之间。
		- 使用神经网络训练线性回归：需要修改代价函数和梯度函数，
			-相较于分类，回归的做法更好一些，提交的MSE为0.051,下一步需要判断神经网络的状态，是处在过拟合还是欠拟合状态。
		- 进一步压缩了数据特征的维度，维度降至450，使用该数据效果有了进一步的提升，MSE降至0.04571
		- 1231提交：更换了激活函数，原有激活函数是sigmoid，更换为ReLU，效果未知		










	- 使用线性回归梯度下降，以4:1划分训练集为训练集和交叉测试集,试下效果如何
		- 不知道该对特征进行多项式交叉(如果全部交叉的话，特征数量多得可怕)。先不交叉试一下效果如何,未完成。
		

